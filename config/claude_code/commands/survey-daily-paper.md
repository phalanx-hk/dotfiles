以下の手順で Huggingface daily papersの$ARGUMENTSの論文を調査してください。

1. huggingface daily_papers APIを使用して、$ARGUMENTSの論文を取得する
  - APIの使い方はhttps://huggingface.co/docs/hub/api#get-apidailypapersを参照
  - fetch APIだとエラーが出るので、curlを使用してAPIを叩いてください

2. 論文のフィルタリングを行う
  - まず、upvoteすうが10件以上の論文に絞ってください
  - 次に、LLM、vision language modelに関する論文に絞ってください
  - それに関連しない論文は全て除外してください
  - フィルタリングした結果論文がなくなったらここで処理を終了してください。
  
3. 取得した各論文ごとに以下の処理を実行する
  - arxivのabsのリンクがあるので、それをHTML版（https://arxiv.org/html/$ID）で開く
    - webfetchツールだとPDFのサイズ制限に引っかかることがあるため、curlを使用してAPIを叩いてください
    - HTML版が利用できない場合は、abstractページから情報を取得
  
  ### 部分的な抽出手法（大きなファイルの効率的な処理）
  - **Abstractの抽出**: `curl -s "https://arxiv.org/abs/$ID" | grep -A 20 "abstract"`
  - **特定セクションの取得**: `curl -s "https://arxiv.org/html/$ID#S2"` （S2はApproachセクション）
  - **キーワード検索**: `grep -A 100 "キーワード" | head -200` で必要な部分のみ抽出
  - **ローカル保存後の処理**: 
    ```bash
    curl -s "https://arxiv.org/html/$ID" > paper.html
    grep -A 20 "提案手法\|Approach\|Method" paper.html
    ```
  - **sedによる範囲指定**: `sed -n '/<section.*id="S2"/,/<\/section>/p'` でセクション単位の抽出
  
  - **重要**: 各論文を個別に分析し、他の論文の内容と混同しないよう細心の注意を払う
  - 論文の内容を正確に理解し、以下のフォーマットに従ってまとめる
  - まとめた内容をMarkdown fileとして出力する

## 分析・執筆時の必須要件

### 提案手法セクションの詳細要件
以下の全ての要素を含めて記述すること：

1. **手法の全体像** - 提案システムの全体アーキテクチャを概説
2. **核心技術の詳細** - 主要な技術要素を番号付きで整理（例：1. データ構築手法、2. 学習アルゴリズム、3. 評価手法）
3. **具体的メカニズム** - 各技術がどう動作するか、ステップバイステップで説明
4. **数式・定式化** - 重要な概念は数式で表現（```math```で囲んで記述）
5. **設計の根拠** - なぜその手法を選択したか、従来手法との違いを明確化
6. **処理フロー** - 段階的な処理プロセスを明示

### 具体性確保のための追加要件
- **具体的なアルゴリズム名**: PPO、Adam、ResNetなど、使用される具体的な技術を明記
- **パラメータ・設定値**: 学習率、バッチサイズ、層の数など具体的な数値を含める
- **実装の詳細**: データ前処理、後処理の具体的手順を記載
- **計算式・擬似コード**: 複雑な処理は擬似コードや計算式で表現

### わかりやすさ向上のための要件
- **専門用語の説明**: 初出の専門用語には簡潔な説明を付加
- **比喩・例示**: 複雑な概念は身近な例や比喩を用いて説明
- **視覚的な表現**: 処理フローは箇条書きや矢印記号で視覚化
- **段階的説明**: 複雑な手法は簡単な概要から詳細へと段階的に説明

### 品質チェック項目
執筆後に以下を自己検証：
- [ ] この論文固有の技術的貢献が明確に記述されているか
- [ ] 他の論文の内容が混入していないか  
- [ ] 技術者が実装可能な程度の具体性があるか
- [ ] 数式や技術用語の使用が適切か
- [ ] 各セクションが論理的に構成されているか
- [ ] 専門知識がない読者でも基本的な理解が可能か
- [ ] 実際に使用されているアルゴリズム・手法名が明記されているか

## 執筆フォーマット
```markdown
# 論文名

## 概要
論文の目的、解決する問題、主要な貢献を500文字程度で簡潔にまとめる。
研究分野と論文の位置づけを明確にする。
**キーポイント**: この研究が何を実現し、なぜ重要なのかを一般読者にも分かるように説明。

## 既存手法の問題点
従来研究の具体的な限界や課題を500文字程度でまとめる。
単なる列挙ではなく、なぜそれが問題なのかの理由も含める。
**具体例**: 「従来のX手法では処理速度がO(n²)であり、大規模データでは実用的でない」など。

## 提案手法

### 1. [手法名]: 全体アーキテクチャ
システム全体の構成と各コンポーネントの関係を説明
- 入力から出力までのデータフロー
- 主要コンポーネントの役割と相互関係

### 2. [核心技術1]: [具体的な技術名（例：改良型Transformer）]
- **目的**: なぜこの技術が必要か（解決する問題を明確に）
- **メカニズム**: 
  1. ステップ1: 入力データの前処理（具体的な正規化手法など）
  2. ステップ2: コア処理（使用するアルゴリズム名と動作原理）
  3. ステップ3: 出力生成（活性化関数、後処理など）
- **数式/定式化**: 

```math
例: Attention(Q,K,V) = softmax(QK^T/√d_k)V
ここで、Q:クエリ、K:キー、V:値、d_k:次元数
```

- **実装詳細**: 
  - 使用ライブラリ/フレームワーク
  - 主要パラメータ（学習率=0.001、バッチサイズ=32など）
- **従来手法との違い**: 
  - 計算量: O(n²)→O(n log n)への改善
  - 精度向上の要因

### 3. [核心技術2]: [技術名]
（上記同様の構造で記述）

### 4. 処理フロー
```
1. データ入力
   ↓
2. 前処理（トークン化、正規化）
   ↓
3. 特徴抽出（CNN/Transformerなど具体的に）
   ↓
4. 中間処理（アテンション機構など）
   ↓
5. 後処理（デコード、スコア計算）
   ↓
6. 出力生成
```

各段階での具体的な処理内容とデータ形式の変化を記述

## 実験結果の概要
定量的結果、ベースラインとの比較、重要な発見を500文字程度でまとめる。
- **主要指標**: 精度XX%向上、処理速度YY倍高速化
- **ベースライン比較**: 既存最高性能のZ手法と比較して...
- **結果の解釈**: なぜこの改善が得られたのか、どの技術要素が最も貢献したか
```

## 注意点
- １論文ずつ調査し、上記のフォーマットでまとめてください
- 複数の論文を同時に調査し、出力することは避けてください
- 不明な技術詳細は推測せず、論文に記載されている範囲で正確に記述
- 読者が実装を再現できるレベルの具体性を目指す